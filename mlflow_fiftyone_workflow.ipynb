{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: #ff6D04; \">MLflow + FiftyOne Workflow</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guided Walkthrough\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "First install the required python libraries below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow fiftyone torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Next we will install the fiftyone-mlflow-plugin that will allow us to view and manage our MLflow client in the FiftyOne App! The App can be run in your browser at localhost:5151 or even in your Databricks Notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fiftyone plugins download https://github.com/jacobmarks/fiftyone_mlflow_plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's kick things off by loading in all of our required libraries. While we are at it, we will start our MLflow client and specifying our `tracking_uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bson import json_util\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "#For Ultralytics\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://127.0.0.1:5000\"\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.operators as foo\n",
    "import fiftyone.plugins as fop\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.utils.random as four\n",
    "\n",
    "from fiftyone import ViewField as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example workflow, I will be using a subset of the [VisDrone](https://github.com/VisDrone/VisDrone-Dataset?tab=readme-ov-file) dataset, a state of the art drone imagery dataset from  Lab of Machine Learning and Data Mining, Tianjin University, China. It features a wide range of locations, time of day, objects, and angles. The subset we will be using can be downloaded on [Google Drive](https://drive.google.com/file/d/1a2oHjcEcwXP8oUF95qiwrqzACb2YlUhn/view). Once the file is downloaded and unzipped, we can load it in by following our ingestor below!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 6471/6471 [469.8ms elapsed, 0s remaining, 13.8K samples/s]      \n",
      "Computing metadata...\n",
      " 100% |███████████████| 6471/6471 [1.1s elapsed, 0s remaining, 6.1K samples/s]         \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_dir=\"./VisDrone-train/VisDrone2019-DET-train/images\"\n",
    "name = \"VisDrone\"\n",
    "\n",
    "# Create the dataset by loading in the directory of images\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dataset_dir,\n",
    "    dataset_type=fo.types.ImageDirectory,\n",
    "    name=name,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# We compute the metadata of the dataset to get height and width of all our samples\n",
    "dataset.compute_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VisDrone features 12 different classes which we will create a dictionary for. The annotations are stored as <x, y, w, h, confidence, label, truncation, occlusion> in txt files. Since it is a custom format, we ingest it by looping through our datasets and grabbing each sample. Next we open up the text file and add the detections and all their metadata on a sample by sample basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0:\"ignore_regions\",\n",
    "             1:\"pedestrians\",\n",
    "             2:\"people\",\n",
    "             3:\"bicycle\",\n",
    "             4:\"car\",\n",
    "             5:\"van\",\n",
    "             6:\"truck\",\n",
    "             7:\"tricycle\",\n",
    "             8:\"awning_tricycle\",\n",
    "             9:\"bus\",\n",
    "             10:\"motor\",\n",
    "             11:\"others\",\n",
    "}\n",
    "\n",
    "ann_dir = \"../VisDrone-train/VisDrone2019-DET-train/annotations/\"\n",
    "\n",
    "for sample in dataset:\n",
    "\n",
    "    # Grab the annotation file\n",
    "    filename = os.path.basename(sample.filepath)\n",
    "    ann = ann_dir + os.path.splitext(filename)[0] + \".txt\"\n",
    "    if os.path.exists(ann):\n",
    "        with open(ann, 'r') as file:\n",
    "            detections = []\n",
    "            for line in file:\n",
    "                split_line = line.strip().split(\",\")\n",
    "                ann_list = [int(x) for x in split_line[:8]]\n",
    "\n",
    "                # Grab all the detection information from the line\n",
    "                label = class_map[ann_list[5]]\n",
    "                trunc = ann_list[6]\n",
    "                occ = ann_list[7]\n",
    "\n",
    "                # FiftyOne takes in normalized (x,y,w,h) bounding boxes\n",
    "                x = ann_list[0] / sample.metadata.width\n",
    "                y = ann_list[1] / sample.metadata.height\n",
    "                w = ann_list[2] / sample.metadata.width\n",
    "                h = ann_list[3] / sample.metadata.height\n",
    "                det = fo.Detection(\n",
    "                    label=label,\n",
    "                    bounding_box = [x,y,w,h],\n",
    "                    truncation=trunc,\n",
    "                    occlusion=occ\n",
    "                )\n",
    "                detections.append(det)\n",
    "\n",
    "            sample[\"ground_truth\"] = fo.Detections(detections=detections)\n",
    "            sample.save()\n",
    "\n",
    "# Set our dataset as persistent\n",
    "dataset.persistent=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading both our images and annotations in, we set the dataset as persistent to have it persist in the database and make sure any new changes will saved. This also allows for easy reloading on future sessions with the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.load_dataset(\"VisDrone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can launch our FiftyOne app with the line below to visualize our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.open('http://localhost:5151/');"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = fo.launch_app(dataset, auto=False)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can begin the data curation process and begin to look for issues or mistakes in our datasets. We can leverage powerful features within FiftyOne to help bring new insights into our dataset and create high quality subsets of our data to train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Visualize embeddings with FiftyOne Brain](https://docs.voxel51.com/user_guide/brain.html#visualizing-embeddings)\n",
    "- [Search your datasets with text prompts or sort by similarity](https://docs.voxel51.com/user_guide/brain.html#similarity)\n",
    "- [Find image quality issues](https://github.com/jacobmarks/image-quality-issues)\n",
    "- [Find exact and approximate duplicates](https://github.com/jacobmarks/image-deduplication-plugin)\n",
    "- [Find outliers in your dataset](https://github.com/danielgural/outlier_detection)\n",
    "- [Create interesting views of your dataset by filtering, slicing, sorting, and more!](https://docs.voxel51.com/user_guide/using_views.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these curation tools, the MLFlow panel and more are powered by [FiftyOne Plugins](https://github.com/voxel51/fiftyone-plugins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created a view you like, we need to export the dataset in YOLO format in order to train YOLO9. We do so by randomly splitting and using the `export` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 1779/1779 [12.3s elapsed, 0s remaining, 126.8 samples/s]      \n",
      "Directory 'VisDrone_curated/' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 6308/6308 [43.9s elapsed, 0s remaining, 91.8 samples/s]       \n",
      "Directory 'VisDrone_curated/' already exists; export will be merged with existing files\n",
      " 100% |█████████████████████| 0/0 [6.2ms elapsed, ? remaining, ? samples/s] \n"
     ]
    }
   ],
   "source": [
    "class_map = {0:\"ignore_regions\",\n",
    "             1:\"pedestrians\",\n",
    "             2:\"people\",\n",
    "             3:\"bicycle\",\n",
    "             4:\"car\",\n",
    "             5:\"van\",\n",
    "             6:\"truck\",\n",
    "             7:\"tricycle\",\n",
    "             8:\"awning_tricycle\",\n",
    "             9:\"bus\",\n",
    "             10:\"motor\",\n",
    "             11:\"others\",\n",
    "}\n",
    "\n",
    "# Replace below with you own saved view, or use the whole dataset\n",
    "#curated = dataset.load_saved_view(\"Curated\")\n",
    "curated = dataset\n",
    "\n",
    "four.random_split(curated, {\"val\": 0.15, \"train\": 0.85})\n",
    "classes = list(class_map.values())\n",
    "\n",
    "for split in [\"val\",\"train\",\"test\"]:\n",
    "    view =  curated.match_tags(split)\n",
    "    view.export(\n",
    "        export_dir=\"VisDrone_curated/\",\n",
    "        split=split,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        classes=classes\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get started, we will be training with Ultralytics YOLOv9. We will take advantage of the Ultralytics MLflow integration to round out our stack for this workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we define some helper functions that help us check to see if an experiment exists on our dataset, and if it does not, create a new one with a serialized version of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_view(view):\n",
    "    \"\"\"\n",
    "    Returns a serilized verision of a view in a json dump\n",
    "\n",
    "    Args:\n",
    "    - view: The name of the view to be serialized\n",
    "    \"\"\"\n",
    "    return json.loads(json_util.dumps(view._serialize()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_exists(experiment_name):\n",
    "    \"\"\"\n",
    "    Checks to see if an experiment exists already\n",
    "\n",
    "    Args:\n",
    "    - experiment_name: The name of the MLflow experiment to check\n",
    "    \"\"\"\n",
    "    return mlflow.get_experiment_by_name(experiment_name) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fiftyone_mlflow_experiment(\n",
    "    experiment_name, sample_collection, experiment_description=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a new MLflow experiment for a FiftyOne sample collection.\n",
    "\n",
    "    Args:\n",
    "    - experiment_name: The name of the MLflow experiment to create\n",
    "    - sample_collection: A FiftyOne sample collection to use as the dataset for the experiment\n",
    "    - experiment_description: An optional description for the MLflow experiment\n",
    "    \"\"\"\n",
    "\n",
    "    tags = {\n",
    "        \"mlflow.note.content\": experiment_description,\n",
    "        \"dataset\": sample_collection._dataset.name,\n",
    "    }\n",
    "    client.create_experiment(name=experiment_name, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we define our core `run_fiftyone_mlflow_experiment` function. This will allow us to pass in our FiftyOne dataset or view and begin a training run. The run will be stored on MLFlow with information of the hyperparameters, dataset contents, and metrics during training like mAP score! A custom run will also be saved to the FiftyOne dataset that saves information like the tracking_uri and experiment name from MLFlow! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.entities.experiment.Experiment"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mlflow.get_experiment_by_name(\"mlflow_fiftyone\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import fiftyone.operators as foo\n",
    "\n",
    "log_mlflow_run = foo.get_operator(\"@jacobmarks/mlflow_tracking/log_mlflow_run\")\n",
    "\n",
    "\n",
    "def run_fiftyone_mlflow_experiment(\n",
    "    sample_collection,\n",
    "    training_func,\n",
    "    experiment_name,\n",
    "    experiment_description=\"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Run an MLFlow experiment on a FiftyOne sample collection using the provided model and training function.\n",
    "\n",
    "    Args:\n",
    "    - sample_collection: A FiftyOne sample collection to use as the dataset for the experiment\n",
    "    - training_func: A function that trains the model and returns it\n",
    "    - experiment_name: The name of the MLflow experiment to create\n",
    "    - experiment_description: An optional description for the MLflow experiment\n",
    "    \"\"\"\n",
    "\n",
    "    client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    if not experiment_exists(experiment_name):\n",
    "        create_fiftyone_mlflow_experiment(\n",
    "            experiment_name, sample_collection, experiment_description\n",
    "        )\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    \n",
    "    # Build a YOLOv9c model from pretrained weight\n",
    "    model = YOLO('yolov9c.pt')\n",
    "    \n",
    "    # Display model information (optional)\n",
    "    model.info()\n",
    "    \n",
    "    # Train the model on the COCO8 example dataset for 100 epochs\n",
    "    training_func(\n",
    "        data='./VisDrone_curated/dataset.yaml',\n",
    "        epochs=1,\n",
    "        imgsz=640,\n",
    "        batch=4,\n",
    "        project=experiment_name,\n",
    "        name=\"example\"\n",
    "    )\n",
    "    # Grab the run that just occurred\n",
    "    run_id = mlflow.search_runs(experiment_names=[\"mlflow_fiftyone\"],\n",
    "                      order_by=[\"start_time DESC\"],).iloc[0].run_id\n",
    "\n",
    "    #Log the completed run to our FiftyOne Dataset\n",
    "    log_mlflow_run(\n",
    "            sample_collection, experiment_name, run_id=run_id\n",
    "        )\n",
    "\n",
    "    run_name =  mlflow.search_runs(experiment_names=[\"mlflow_fiftyone\"],\n",
    "                      order_by=[\"start_time DESC\"],).iloc[0][\"tags.mlflow.runName\"]\n",
    "\n",
    "    # Add predictions to FiftyOne dataset\n",
    "    sample_collection.apply_model(model, label_field=run_name)\n",
    "\n",
    "    # Save run to the labels\n",
    "    for sample in dataset:\n",
    "        sample[run_name].run_id = run_id\n",
    "        sample.save()\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we pass in our dataset or view, our training function, and the name of the experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a YOLOv9c model from pretrained weight\n",
    "model = YOLO('yolov9c.pt')\n",
    "\n",
    "# Display model information (optional)\n",
    "model.info()\n",
    "\n",
    "run_fiftyone_mlflow_experiment(dataset,model.train, \"mlflow_fiftyone\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our run, we can monitor its status in the FiftyOne App through the MLFlow panel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/mlflow.gif\" alt=\"MLFLow Monitoring\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also track which runs have been performed on our dataset! Use the `get_mlflow_experiment_info` operator to find all the MLflow information stored on the dataset such as `tracking_uri`, `experiment_name`, and `runs`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/view_mlflow.gif\" alt=\"MLFlow Monitoring\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also stored in our predictions on our dataset the `run_id` associated with them. It is always easy to access the `run_id` with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'346a36c0f62f415cb342ea4bfc024952'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sample = dataset.first()\n",
    "\n",
    "#sample.(prediction_label).run_id returns run_id for those predictions\n",
    "first_sample.example.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Our Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use `evaluate_detections` and calculate the mAP of our model. We also add metadata to our sample detections such if they were a false potive or a true positive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 6471/6471 [20.0m elapsed, 0s remaining, 6.6 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 6471/6471 [6.8m elapsed, 0s remaining, 14.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "results = dataset.evaluate_detections(pred_field=\"predictions\", gt_field=\"ground_truth\", eval_key=\"eval\", compute_mAP=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can repeat the workflow of adding predictions and evaluating for any number of models on our dataset! You can even compare predicitions from one model to another using the [model comparision](https://github.com/allenleetc/model-comparison) plugin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/model_compare_input.gif\" alt=\"Model Compare Input\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can choose from a variety of options to see exactly where your two models differ. Forget searching across hundreds of thousands of detection, the model comparision plugin will bring only the samples of interest right in front of you! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/model_compare_out.gif\" alt=\"Model Compare Input\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A trained model can also help use during data curation! One of the most common ways is to check your high confidence false postives. This is where you are most likely to find annotation mistakes in your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/high_cf_fp.gif\" alt=\"High Conf False Positives\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
